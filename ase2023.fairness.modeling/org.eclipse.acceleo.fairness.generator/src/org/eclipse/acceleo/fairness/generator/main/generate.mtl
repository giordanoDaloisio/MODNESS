[comment encoding = UTF-8 /]
[module generate('http://www.example.org/fairness')]


[template public generateFairnessModel(biasModel: GroupAnalysis )]

[comment @main/]
[file (biasModel.name + '.py', false, 'UTF-8')]
from FairnessMetric import FairnessMetric, binarize

import pandas as pd
from operators import SingleOperator



file_path = '[biasModel.dataset.filePath/]'
predicted_label_name = '[biasModel.dataset.predictedLabelName/]'
ground_truth_label_name = '[biasModel.dataset.groundTruthLabelName/]'
data = pd.read_csv(file_path)



[for(val: DatasetSensitiveVariable | biasModel.dataset.datasetSentiveVariable)]

[for (op: SingleOperator | val.datasetsensitivevariablevalue.operator.oclAsType(SingleOperator))]

operator_value = [op.value /]
[if (op.operator = SingleOperatorParameter :: GREATER_EQUAL)]
operator = SingleOperator.GREATER_EQUAL
[/if]
binarize(data, '[val.name /]', operator, operator_value, [val.datasetsensitivevariablevalue.relativeToDatasetSize.toString().toUpperFirst()/])
[/for]
[/for]



[for(val: DatasetPositiveOutcome | biasModel.dataset.positiveOutcome)]

[for (op: SingleOperator | val.operator.oclAsType(SingleOperator))]

operator_value = [op.value /]
[if (op.operator = SingleOperatorParameter :: GREATER_EQUAL)]
operator = SingleOperator.GREATER_EQUAL
[/if]
binarize(data, '[val.name /]', operator, operator_value, [val.relativeToDatasetSize.toString().toUpperFirst()/])
[/for]
[/for]




[if biasModel.dataset.datasetSentiveVariable -> size()>1]
indexes = ['['/]
[for(val: DatasetSensitiveVariable | biasModel.dataset.datasetSentiveVariable)]
'[val.name/]',
[/for]
[']'/]
dataset_unprivileged_group = {'indexes['['/]0[']'/]': 0, 'indexes['['/]1[']'/]' : 0}
dataset_privileged_group = {'indexes['['/]0[']'/]' : 1, 'indexes['['/]1[']'/]' : 1}
dataset_positive_outcome = 1
[/if]
[if biasModel.dataset.datasetSentiveVariable -> size()=1]
[for(val: DatasetSensitiveVariable | biasModel.dataset.datasetSentiveVariable)]
dataset_unprivileged_group = {'[val.name/]': 0}
dataset_privileged_group = {'[val.name/]' : 1}
dataset_positive_outcome = 1
[/for]
[/if]


[if biasModel.metric -> size()>0]
[for (metric: Metric | biasModel.metric)]
[if (metric.operator.oclIsTypeOf(SingleOperator))]
threshold = [metric.operator.oclAsType(SingleOperator).value/]
[/if]
[/for]
[/if]

tolerance_value = [biasModel.metric.toleranceValue/]


metrics = FairnessMetric(data, dataset_unprivileged_group, dataset_privileged_group,
                         ground_truth_label_name, predicted_label_name, dataset_positive_outcome)


[for (metric: Metric | biasModel.metric)]

[if (metric.function.oclIsTypeOf(ExistingFairnessMetric))]

[if (metric.function.oclAsType(ExistingFairnessMetric).metric = FairnessMetric :: STATISTICAL_PARITY )]
print(metrics.statistical_parity_difference())
if abs((metrics.statistical_parity_difference()) > threshold + tolerance_value):
    print("The dataset is biased")
else:
    print("The dataset is fair")
[/if]
[if (metric.function.oclAsType(ExistingFairnessMetric).metric = FairnessMetric :: EQUALIZED_ODDS )]
print(metrics.equal_opportunity_difference())
if abs(metrics.equal_opportunity_difference()) > threshold + tolerance_value:
    print("The dataset is biased")
else:
    print("The dataset is fair")
[/if]
[/if]
[if (metric.function.oclIsTypeOf(ExistingFairnessMetric)= false)]
[metric.name/] = metrics.group_size(
    'frequency == 0 and ranking == 1')/metrics.group_size('ranking == 1')

print(coverage)
if(abs(coverage) < threshold + tolerance_value):
    print("The dataset is biased")
else:
    print("The dataset is fair")

[/if]
[/for]

[/file]

[file ('FairnessMetric.py', false, 'UTF-8')]


from aif360.metrics import ClassificationMetric
from aif360.datasets import BinaryLabelDataset
import pandas as pd
import math


def summation(startRange, endRange, body):
    ris = 0
    for i in range(startRange, endRange):
        ris += body(i)
    return ris


def logaritm(x):
    return math.log(x)

def binarize(df: pd.DataFrame, column: str, operator: Operator, value: float, relative_to_df=False):
    if relative_to_df:
        df.sort_values(by=['['/]column[']'/], inplace=True, ascending=False)
        position = len(df) - int(len(df) * value)
        if operator == SingleOperator.GREATER:
            df.iloc['['/]:position, df.columns.get_loc(column)[']'/] = 1
            df.iloc['['/]position:, df.columns.get_loc(column)[']'/] = 0
        elif operator == SingleOperator.MINOR:
            df.iloc['['/]:position, df.columns.get_loc(column)[']'/] = 0
            df.iloc['['/]position:, df.columns.get_loc(column)[']'/] = 1
        elif operator == SingleOperator.GREATER_EQUAL:
            df.iloc['['/]:position+1, df.columns.get_loc(column)[']'/] = 1
            df.iloc['['/]position+1:, df.columns.get_loc(column)[']'/] = 0
        elif operator == SingleOperator.MINOR_EQUAL:
            df.iloc['['/]:position+1, df.columns.get_loc(column)[']'/] = 0
            df.iloc['['/]position+1:, df.columns.get_loc(column)[']'/] = 1
    else:
        if operator == SingleOperator.GREATER:
            df.loc['['/]df['['/]column[']'/] > value, column[']'/] = 't'
            df.loc['['/]df['['/]column[']'/] != 't', column[']'/] = 0
            df.loc['['/]df['['/]column[']'/] == 't', column[']'/] = 1
        elif operator == SingleOperator.MINOR:
            df.loc['['/]df['['/]column[']'/] < value, column[']'/] = 't'
            df.loc['['/]df['['/]column[']'/] != 't', column[']'/] = 0
            df.loc['['/]df['['/]column[']'/] == 't', column[']'/] = 1
        elif operator == SingleOperator.GREATER_EQUAL:
            df.loc['['/]df['['/]column[']'/] >= value, column[']'/] = 't'
            df.loc['['/]df['['/]column[']'/] != 't', column[']'/] = 0
            df.loc['['/]df['['/]column[']'/] == 't', column[']'/] = 1
        elif operator == SingleOperator.MINOR_EQUAL:
            df.loc['['/]df['['/]column[']'/] <= value, column[']'/] = 't'
            df.loc['['/]df['['/]column[']'/] != 't', column[']'/] = 0
            df.loc['['/]df['['/]column[']'/] == 't', column[']'/] = 1
        df['['/]column] = df['['/]column[']'/].astype(np.float64)

class FairnessMetric(ClassificationMetric):

    def __init__(self, df: pd.DataFrame, unprivileged_groups: dict, privileged_group: dict, true_label_name: str, predicted_label_name: str, positive_value: int):
        
        super().__init__(self.dataset_true, self.dataset_pred,
                         unprivileged_groups=['['/]unprivileged_groups[']'/], privileged_groups=['['/]privileged_group[']'/])

    def probability(self, object: str, condition: str = '') -> float:
        probability = self.df.query(object).shape['['/]0[']'/] / self.df.shape['['/]0[']'/]
        if condition == '':
            return probability
        else:
            self.df = df
        if true_label_name != "" and predicted_label_name != "":
            self.dataset_true = BinaryLabelDataset(
                df=self.df.drop(columns=['['/]predicted_label_name[']'/]),
                label_names=['['/]true_label_name[']'/],
                protected_attribute_names=list(unprivileged_groups.keys()),
                favorable_label=positive_value,
                unfavorable_label=1 - positive_value,
            )
            self.dataset_pred = self.dataset_true.copy(deepcopy=True)
            self.dataset_pred.labels = self.df['['/]predicted_label_name[']'/].values.reshape(
                -1, 1
            )
        elif true_label_name != "":
            self.dataset_true = BinaryLabelDataset(
                df=self.df,
                label_names=['['/]true_label_name[']'/],
                protected_attribute_names=list(unprivileged_groups.keys()),
                favorable_label=positive_value,
                unfavorable_label=1 - positive_value,
            )
            self.dataset_pred = self.dataset_true.copy(deepcopy=True)
        elif predicted_label_name != "":
            self.dataset_true = BinaryLabelDataset(
                df=self.df,
                label_names=['['/]predicted_label_name[']'/],
                protected_attribute_names=list(unprivileged_groups.keys()),
                favorable_label=positive_value,
                unfavorable_label=1 - positive_value,
            )
            self.dataset_pred = self.dataset_true.copy(deepcopy=True)
            return (self.df.query(condition + ' and ' + object).shape['['/]0[']'/]/self.df.shape['['/]0[']'/]) / probability

    def expected_value(self, column_name: str, condition: str = '') -> float:
        subdata = self.df['['/]column_name[']'/]
        if condition == '':
            expected_value = 0
            for val in subdata.unique().tolist():
                expected_value += val * \
                    self.probability(column_name + ' == ' + str(val))
            return expected_value
        else:
            expected_value = 0
            for val in subdata.unique().tolist():
                expected_value += val * \
                    self.probability(column_name + ' == ' +
                                     str(val), condition)
            return expected_value

    def group_size(self, groupCondition: str = '', variable: str = ''):
        if groupCondition != '':
            return self.df.query(groupCondition).shape['['/]0[']'/]
        elif variable != '':
            return len(self.df['['/]variable[']'/].unique())
        return 0

    def dataset_size(self):
        return self.df.shape['['/]0[']'/]
[/file]

[file ('operators.py', false, 'UTF-8')]

from enum import Enum


class Operator(Enum):
    pass


class SingleOperator(Operator):
    GREATER = '>'
    MINOR = '<'
    GREATER_EQUAL = '>='
    MINOR_EQUAL = '<='


class RangeOperator(Operator):
    IN_INCLUDED = 'IN_INCLUDED'
    IN_EXCLUDED = 'IN_EXCLUDED'
    IN_LOWER_INCLUDED = 'IN_LOWER_INCLUDED'
    IN_GREATER_INCLUDED = 'IN_GREATER_INCLUDED'

[/file]

[/template]
